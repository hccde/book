深入理解计算机系统
四个抽象
cpu 抽象成 进程
程序存储器 抽象成 虚拟内存
io设备抽象成 文件
计算机 抽象成 虚拟机

抽象是为了掩盖实现的差异

指针的字节数和寻址空间的能力一致 因为你的指针可以指向可寻址空间的任何一处地方 所以指针的字节数等于寻址空间 在32位机器上是4个字节 4*8 在64位机器上是8个字节

对于不同编译器 int 一般都是四位字长 long int的长度则不一定 取决于编译器 采用 LP4模型的 是64 如linux上 long long int 和 long int 一样长 都是64 而在 vs 上 则是 long int 为32  long long int 是64 采用的是 LLP模型

大端机  小端机  0x1234  34是低位 12是高位 
大端机表示为 12 34
小端机表示为 34 12
大小端在socket编程 强制类型转换比较敏感 但是一但操作系统确定了 这个就确定了 尽管现在允许编程为大端机 小端机

交换两个变量的值不一定需要第三个变量 利用布尔代数可以完成只要两个变量之间相互运算就可以
int *a int *b  
*b = * a ^  *b;
*a = *a ^ *b;
*b = *a ^ *b;
即完成交换 使用了 布尔代数（a^b)^a = b

 左移都是*2 空位用0弥补 都是逻辑左移 
右移分为逻辑右移  算术右移 对于有符号数 都是算术右移动 对于无符号数是逻辑右移 算术移动在空位处补最高有效位  逻辑右移就是 补0

当移位的位数大于类型的位数 比如32位移动大于32位时 对于c来说 是ub 对于java来说 则会计算 k mod w 来得到的 k是要移动的位数 w是类型的位数

有符号数的首位可以看成是一个 拥有权重为 -2^w的位



在强制转换的时候 数的位级并不会发送改变 改变的只是解释这个数的方式

对于无符号数和有符号数 相运算 c语言会将 有符号数转为无符号数再进行预算 并假设两个数都是非负的


why?
假设字长为一字节
负数在计算机中是用反码表示的 可 -0 也就是原码为 1000 0000的数是会产生进位的 忽略进位 为 0000 0000 这也是+0的补码表示 相对应的 补码为 1000 0000的码需要借位，进位可以忽略 但是借位就难办了 因此 补码为 1000 0000的码没有对应的原码 所以用作最小值 同样的道理：
1000000000000000的原码不存在 于是用作负的最大值

为什么要用补码来表示 因为 二进制加法 没有符号直接相加即可 可是有符号则不能直接相加 因为符号的原因 导致带符号加法 和无符号加法不同 导致要两种加法电路 这很浪费 因此 我们在上面一层用补码来表示可以简化电路设计
此外还有一个原因 就是用原码来表示的话 +0 和 -0 还要区分 一个是 1000 0000 一个是 0000 0000

类型相加 有正溢出和负溢出 正溢出小于任何一个加数 负溢出....

两个数相乘是mod了一个2^w的

乘法的时钟周期比较长 被变成移位和加法 即便发生溢出也只取低位的 结果也对 编译器会将乘法优化成移位

除法的时间也更久 除以2 我们可以表示为移位 但是不是任意的k 都可以表示为移位

浮点数阶码的存储是 val - 127 （8位阶码）也就是阶码最高位决定了 exp是正的还是负的

浮点数 规定尾数不能为以0 开头 所以尾数从0开始的称为非规格化数 因此有了最小非规格化数 最大非规格化数 最小规格化数 最大规格化数 再加上+0 -0 无穷大 NAN。非规格化数可以平滑过渡到规格化数 这归功于我们的阶码的表示是 val-127 不然的话规格化数就是从1开始的

向偶数舍入 比向上舍入或者向下舍入要更接近平均值
四舍五入对于0.5的情况的思考

浮点数运算不具有结合性的群属性

重用要基于它所依赖的假设

超线程 多核 的概念
机器层面 汇编语言 没有数据和指针的区别 也没有类型的区别

x86-64的指令长度从1到15字节不等 常用的指令以及操作数较少的指令所需要的字节较少

寻址方式 n多种 复杂的寻址在处理数组等比较方便

lea mov 一个传值 一个传地址
mov %eax [0x100] ;把[0x100] 的值传到eax 中去
lea %eax [0x100] ;把 0x100 传到 eax 中去
lea 可以用来加速加法乘法运算 [0x100]可以是很复杂的寻址 计算出来的有效偏移 因此可以用来放一些计算式
lea %eax [%eax,%eax,2] ;就是计算 [eax]+2*[eax]

inc %esp 将栈顶指针加1
和 
inc [%esp] 将栈顶的值加1

inc 和 dec 不影响 cf 标志位  
intel 在硬件层面就是这样设计的 有intel 工作人员说 inc dec 用在循环中 如果设置cf 位 循环中的计算也可能设置cf 因此 会产生冲突

无条件跳转 有条件跳转 有条件跳转根据标志寄存器中的内容来决定如何跳转

跳转可能可能会在处理器上非常低效，why ,缓存失效，指令预取失效，的问题，寄存器内容要重新装填 出栈入栈操作等等 所以一种替代的策略是使用数据的条件转移
我们把两种分支可能的结果都算出来 然后根据条件决定使用哪个数据，当然，这种策略是受限的

当 x86-64 所需要的数据超过寄存器所要的大小的时候就会在栈上分配空间 这个部分称为栈帧

p调用q p的栈帧里有q的返回地址  如果q需要的参数小于6个（64）那么直接放在寄存器里 如果大于6个则 放在q的栈帧之中
有些子过程甚至不需要参数 因为其参数小于6个 局部变量很少 也不调用其他的子过程 所以只需要用到寄存器就可以了
 
 局部数据必须放在内存之中的情况
 寄存器耗尽
 局部变量有取地址操作因而必须产生一个内存地址
 局部变量是结构或者数组 同二（必须要有地址）

 call 和 ret 修改了pc指针 对于栈帧是由调用者维护的

 子过程的调用 push 和 pop 所使用的寄存器 注意入栈顺序和出栈顺序

 时钟周期 指令周期 机器周期
 时钟周期是系统时钟频率的倒数
 机器周期是取指令 译码 执行 访问内存 写回 更新等 这整个过程需要的时钟周期
 指令周期是 执行一条指令所需的时间 不同的指令的指令周期不一样 对于简单的指令 可能指令周期就等于一个机器周期 对于复杂的指令 指令周期等于多个机器周期

指令的吞吐量 1条指令 / 一条指令所要的时间

在指令设计的时候 我们希望指令能共用硬件 从而简化设计 

流水线 超标量
流水线 的时钟周期不能过快 想象一下生产线上的生产阶段 其生产时间可能是不确定的 如果按最快的频率 则会产生生产事故 因此流水线的时钟频率很重要
超标量 指令并行 乱序发射

流水线的cpu 设计 带来了 相关指令的 冒险 下一条指令要用到上一条指令的结果 但是 在流水线中上一条指令还没有来得及把结果写回寄存器 因此 产生问题 这时候可以添加nop 指令 

避免冒险的手段：
一：数据冒险
1.暂停指令  等待指令所需要的数据写回
2.转发 来避免数据冒险 转发未写回的值 需硬件支持 将新计算出来的值传回译码阶段
3. 有些数据冒险不能使用单纯的转发来解决 因为内存读在流水线中发生的比较晚 已经过了需要它的指令的执行时间 这个时候 即便已经拿到这个值也已经来不及了 因为流水线已经把需要这个数据的指令执行过了。解决办法是 用暂停和转发一起。在需要的指令执行之前用气泡暂停它然后等待 比如从内存读取的值的转发。这种使用暂停来处理加锁/使用冒险的方法称为加载互锁（load interlock）加载互锁和转发技术结合起来可以处理所有类型的数据冒险。

二 控制冒险
主要是因为指令中有一些分支判断 在流水线中我们预取 译码的 指令可能是错误的 分支预测可能并不准确。已经ret指令的返回，都可能造成控制冒险
在分支预测中 不同处理器采用的策略不同 最简单的 任意选一条分支 一般是第一个分支 错误了就异常处理
1.暂停 当ret经过译码 执行和访存阶段时，流水线应该暂停，在处理过程中插入三个气泡，一旦ret 指令达到写回阶段 pc渲染逻辑就会选择返回地址作为指令的取址地址

流水线中的异常处理
当分支预测出错 或者访问内存出错
因为我们在流水线寄存器中维护了一个stat状态 一旦一条指令在处理过程中发生异常 则设置它 这时候所有的指令都不允许写寄存器 携带异常信息的指令通过流水线

浮点计算 乘法 除法需要更多的指令周期 一般将其独立于主流水线之外

一个典型的处理器拥有两个第一层高速缓存 一个用于读指令。一个用于读和写数据。另一种类型的高速缓存存储器 称为翻译后备缓冲器 （TLB）它提供了从虚拟地址到物理地址的快速翻译。问题在于缓存不命中 这个时候可能要将处理器暂停 等待从更高的缓存中读取数据

高速缓存的更新 如何缓存 切换进程会不会造成高速缓存失效？ 缓存的是物理地址还是虚拟地址 两者的差别和问题 参见wiki

程序优化的时候内存别名使用 优化不一定能产生正确的代码：
例如 swap 优化
*xp = *xp + *yp
*yp = *xp - *yp
*xp = *xp - *yp
如果xp 和 yp 指向的是同一块内存 则会产生问题 修改了xp 也就修改了 yp

函数有副作用的话 编译器的优化很可能不是正确的 编译器不会去检查函数是否存在副作用

gcc 只在单个文件中尝试函数内联 （也就是分模块的不会进行函数内联）

在大循环中 引入临时变量保存中间结果 而不用每次都保存到待求的指针变量中去 减少内存读取
比如 
while(...){
	*p+=1;
}
与
int tem = *p;
while(...){
	tem+=1;	
}
*p = tem;

下面一个更快 为什么
因为 第一个有指针 则必须对应内存中的一个地址 所以编译器每次都会取内存数据 写内存数据 第二个 则不必 可以将其放到寄存器中

cpu的退役单元 retirement unit 用来监测程序是否按指令执行（预取失败 指令并行	）
任何对程序寄存器的更新都会在指令退役之后发生。我们可以把指令看成是一批一批执行的 错了就回滚，对了就更新程序寄存器

循环展开为什么能加速程序执行 利用指令并行执行来加速 唯一的关键在于 要注意不能有相关性

从内存加载数据会影响预算的速度 因为后面的计算依赖于加载这个动作 而写回则不会 除非一个内存读 依赖于一个内存写

总结一下优化程序的方法：
选择合适的算法
编码原则：
消除连续的函数调用 比如将循环中的可以提出的函数调用 提取出来
消除不必要的内存引用 代之以临时变量
循环展开 利用流水线和指令并行加速代码执行
用条件数据代替条件控制 提高分支预测的准确度

DRAM 和 SRAM SRAM是静态的随即存储器 它具有双稳态特性，只要有电，它会永远保持它的值，常用来做高速缓存 或者cpu 片内存储
DRAM 需要不停的读写刷新 常用来做主存，有的系统会在其中加入纠错位 从而发现并纠正任何单个的错误位

只要供电 sram就永远不会变。与dram不同 它不需要刷新，sram的存储比dram快，代价是要用更多晶体管和耗能大 价格贵

设计者将dram组织成二维阵列而不是线性数组的一个原因是降低芯片上地址的引脚数量。二维阵列组织的缺点是必须分成两步发送地址

ROM:
PROM:可编程rom  只能被编程一次
EEPROM：可擦可写可编程rom
flash memory


总线设计

最早的磁盘设计是为面密度很低的时候设计的，现在的面密度很高，磁盘扇区之间的间隔变得不可接受的大，因此现代大容量磁盘采用 多区记录
磁盘容量计算 柱面 扇区 磁道
磁盘寻道 旋转延迟 基本上相同 *2
磁盘格式化的目的 磁盘的备用扇区 格式化之后的磁盘小于实际的磁盘的容量

IO总线 系统总线 内存总线

IO总线非常多 
常见的有比如 USB总线 SCSI总线  PCI总线 PCIe总线 SATA总线

cpu的内存映射I/O

ssd读的时间非常快 写的时间很慢 首先因为写之前要擦除 而且写一个页 必须将这个页所属的块的其他带数据的页全部移动到一个擦除过的块 然后才能写

局部性原理
一个编写良好的计算机程序常常具有良好的局部性。也就是，它倾向于引用邻近的其他最近引用过的数据项的数据
时间局部性 和 空间局部性（比如数组访问）

文件系统 -- 实现

高速缓存命中 和 冲突不命中 带来的 抖动
高速缓存采用了简单的hash来做内存缓存命中
为什么高速缓存采用中间位作为组索引 因为如果采用高位的话 相邻的块会被缓存到高速缓存的同一个组中 那么对于一个空间局部性很好的程序 顺序扫描一个数组的时候 任何时刻 高速缓存都利用了集中的那个块 也就是散列的程度不好 高速缓存没有利用起来 很容易抖动 反复换进换出同一个高速缓存块。

越往存储器的下端走 缓存不命中的代价越高 复杂的缓存策略越必须

全相联高速缓存 组相联高速缓存

缓存一致性的问题 读 写  直接写 写回 两种策略
如何写不命中 分为两种方法 一种是写分配 加载相应第一层的块到高速缓存中 然后更新这个高速缓存。写分配试图利用写的空间局部性 但是缺点是每一次不命中都会导致一个块从低的一层传送到搞的一层。另一种方法称为 非写分配 避开高速内存 直接把这个字写到低一层中。直写高速缓存通常是非写分配，写回高速缓存通常是写分配的。

程序中小步长是符合优化的 因为步长小容易在较高层次的存储器结构中被缓存命中

程序 分块 的概念 将程序中经常使用的的数据丢到一个数组中 然后在循环中访问 可以提高缓存命中

c 的静态变量在代码段中分配
函数的静态变量 只有函数作用域可见
任何带有static的变量或者函数都是模块私有的

重载一般由重整来实现的 函数名 加上 参数的类型进行某种编码

linux上的编译器在对待重复跨模块的全局变量时候不会直接报错 而是会根据强弱规则来选择 比如初始化的要比未初始化的强 .bss .common段

.text 段  已编译的机器代码
.rodata 只读数据 比如printf语句中的格式串和开关跳转表
.data 已初始化的全局和静态c变量 局部c变量在运行时被保存在栈中，既不出现在.data 也不出现在.bss
.bss 未初始化的全局和静态C变量，以及所有被初始化为0的全局或静态变量。在目标文件中这个节不占据实际空间。它仅仅是一个占位符。目标文件格式区分已初始化和未初始化是为了空间效率。在目标文件中，未初始化变量不需要占据任何实际的磁盘空间。运行时在内存中分配这些变量，初始值为0
.rel.text 一个.text节中位置的列表 放重定位信息的,方便链接器使用
.rel.data 被模块引用或者定义的所有的全局变量的重定位信息。一般而言 任何已经初始化的全局变量 如果它的初始值是一个全局变量地址或者都需要被修改
.symtab 一个符号表 存放在本模块中定义的函数和全局变量的信息

内存对齐 涉及到虚拟内存 内存分页 缺页中断

共享动态链接库的全局数据是在调用者自己的bss段内的 改变并不会影响其他的数据 （可以尝试 static 看看能否共享这个数据） 共享的是代码段

GOT PLT
为什么需要 GOT呢 因为动态链接库是代码共享 代码段是只读不可写的 因此我们不能去在动态链接的时候重定位它的地址 但是数据段是可以更改的 所以想到用数据段来做重定位

编译时，-fPIC编的是.so文件，这个文件也是要访问外部变量的，但是链接它程序很多，它里面的地址不能写死。  以下引用一段话，关键第一句：     对于模块外部引用的全局变量和全局函数，用 GOT表的表项内容作为地址来间接寻址；对于本模块内的静态变量和静态函数，用 GOT表的首地址作为一个基准，用相对于该基准的偏移量来引用，因为不论程序被加载到何种地址空间，模块内的静态变量和静态函数与GOT 的距离是固定的，并且在链接阶段就可知晓其距离的大小。这样，PIC 使用 GOT来引用变量和函数的绝对地址，把位置独立的引用重定向到绝对位置。

动态链接库要映射到调用它的程序中去 每个调用它的程序的要映射的地址都不同 因此不能直接映射 但是代码间的相对地址是固定的 所以通过GOT 定义与GOT的偏移
我们也能完成寻址 同而又能各自映射

这样来理解 现在有一个共享链接库，它有部分代码要暴露在外给调用它的模块引用 它是以映射进调用者的内存空间的方式来调用的 在运行的时候要修改地址 重定位方便调用者 而GOT里面就是偏移。动态链接库不知道它会被映射到调用者的哪个位置 因此它只使用相对于偏移
PLT是延迟绑定技术
内存共享的页面是以页表的方式共享的 
PLT 延迟绑定的动机是对于一个像libc.so这样的动态共享库输出成百上千个函数中，一个典型的应用程序只会使用其中很少的一部分 所以不用一开始全部都绑定
PLT 和 GOT 的相互调用 以及最开始的时候 GOT里面的地址是未修改的 只是简单的指向对应PLT的下一个个指令 下一个指向是压入调用函数的id 然后压入动态链接器的参数 然后动态链接器使用这两个参数来重写地址 然后跳转到改地址执行

link链接器支持的打桩机制